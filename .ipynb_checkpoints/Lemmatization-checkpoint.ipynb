{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f58826b-d2f9-4c2e-bb04-643fe59a8832",
   "metadata": {},
   "source": [
    "# Wordlemmatizer\n",
    "\n",
    "A word lemmatizer is a tool used in Natural Language Processing (NLP) to reduce words to their base or dictionary form, known as the lemma. Unlike stemming, which simply removes suffixes, lemmatization considers the context and part of speech to ensure the word is transformed into a meaningful root form.\n",
    "For example:\n",
    "- \"running\" → \"run\"\n",
    "- \"mice\" → \"mouse\"\n",
    "- \"was\" → \"be\"\n",
    "Lemmatization is widely used in text analysis, search engines, and chatbots to improve understanding and processing of language. If you're interested in implementing it, Python libraries like NLTK, spaCy, and TextBlob offer powerful lemmatization tools. Want to try it out? I can guide you!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04113c19-8c13-4fd6-8749-f30bf6d36621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Keshav\n",
      "[nltk_data]     Barawal\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0a65ebe-932b-4b86-894c-624355dbc519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d03839fc-83d3-43e7-b4c1-ce60028af495",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37afb2be-7a6a-45c6-9245-24e1a33e7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a52a101-fb8e-43bc-86e9-ebb947194fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "eats ---> eat\n",
      "eaten ---> eat\n",
      "writing ---> write\n",
      "writes ---> write\n",
      "programming ---> program\n",
      "programs ---> program\n",
      "history ---> history\n",
      "finally ---> finally\n",
      "finalized ---> finalize\n"
     ]
    }
   ],
   "source": [
    " for word in words:\n",
    "     print(word,\"--->\",lemmatizer.lemmatize(word,pos = 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8da991-6dee-4d96-a50d-587f46d76f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
